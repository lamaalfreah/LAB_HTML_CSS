<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Revolution</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
</head>
<body>
  <header class="text-white text-center py-4 bg-dark">
    <h1>🤖 The AI Revolution</h1>
    <p>Exploring the Rise of Artificial Intelligence</p>
  </header>

  <nav class="bg-light py-2">
    <ul class="nav justify-content-center">
      <li class="nav-item"><a class="nav-link" href="#intro">Introduction</a></li>
      <li class="nav-item"><a class="nav-link" href="#what-ai">What is AI?</a></li>
      <li class="nav-item"><a class="nav-link" href="#intelligence">Just How Intelligent is AI?</a></li>
      <li class="nav-item"><a class="nav-link" href="#jobs">Will AI Take Our Jobs?</a></li>
    </ul>
  </nav>

  <main class="container my-5">
    <article>
      <section id="intro" class="mb-5">
        <h2>Introduction</h2>
        <p>
            In the last few years, artificial intelligence (AI) has moved from a futuristic concept to a powerful technology reshaping our everyday lives. AI tools are driving cars, detecting credit card fraud, scanning X-rays for fractures, composing music—even “helping” kids with their homework.<br>
            <br>
            As AI tools grow more powerful and mainstream, urgent questions abound about their impact—on jobs, creativity, and the way we understand ourselves. The hype can lead many down AI doomsday rabbit holes, according to University College Cork computer scientist Barry O’Sullivan, an expert in AI and ethics<br>
            <br>
            “Frankly, I wish the world would calm down a little bit when it comes to AI,” O’Sullivan said at a recent IPR talk. “It's not going to kill us all. It's not going to take all of our jobs.” <br>
            <br>
            To better understand AI and the changes coming with it, IPR collected insights from faculty experts about how they are using and studying AI, what they are learning, and what the future might hold. They stress that AI’s future will be shaped not just by technology itself, but by how we choose to use and regulate it.
        </p>
        <img src="https://urbeuniversity.edu/post_assets/Le9zsr8bQmv7gmZW40UXiVaPsGcpVwaY65mw28tU.webp" alt="AI Graphic" class="img-fluid rounded">
      </section>

      <section id="what-ai" class="mb-5">
        <h2>What is AI?</h2>
        <p>
            “‘Artificial intelligence’ is a pretty weaselly term,” IPR computational linguist Rob Voigt said. “It can mean lots of different things to lots of different people.”<br>
            <br>
            Many machine learning techniques, including common statistical models like regression, can be considered AI. The distinction, Voigt explains, often comes from how a system is used. AI typically refers to a machine performing tasks traditionally done by people.<br> 
            <br>
            The term was coined in a 1955 research proposal by a group of scientists who said they sought “to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves.” <br>
            <br>
            Today, Voigt and his colleagues at Northwestern’s Linguistic Mechanisms Lab use machines to identify trends in vast amounts of text and speech, including police interactions and 911 calls.<br>
            <br>
            With human labor alone, these analyses would take much longer, because researchers would have to read or listen to each conversation and manually annotate each one.<br>
            <br>
            “There’s too much data for a human being to look at every example that we want someone to look at,” he explained. 
            <br>
            Voigt’s research team has trained algorithms to recognize respect in human interactions—for example, noting when someone is addressed as “sir” rather than “dude”—but detecting more subtle conversational nuances is an ongoing challenge.<br>
            <br>
            “Anything that you can imagine asking a human to do, we can train an artificial intelligence to do,” he said. “The question—and this is essential—is how well is it possible to make that work?” <br>
            <br>
        </p>
      </section>

      <section id="intelligence" class="mb-5">
        <h2>Just How Intelligent is AI?</h2>
        <p>
            AI tools like ChatGPT project the persona of a pleasant, eager-to-please assistant, but can they really “think” the way we do?<br>
            <br>
            IPR computer scientist Jessica Hullman, who studies how AI can support human decision making, says that AI tools carry their creators’ flaws and biases. And the way that the models are adjusted after training to align with human preferences both strengthen and weaken these AI tools.<br>
            <br>
            “The models start to be very good at creating things that humans like,” she said.<br>
            <br>
            “It makes them more persuasive,” Hullman explained. “They get better at things like apologizing for their lack of information—but they also get better at things like sounding authoritative, because people like when things sound more authoritative.”<br>
            <br>
            Even with advanced technologies like generative AI, human decisions—such as selecting training data and setting development priorities—play a fundamental role.<br>
            <br>
            “AI models don’t think like humans,” said management scholar and IPR associate Hatim Rahman. “They’re giving statistically probable results, which often are coherent, but ultimately we are the ones who are going to determine whether its output is intelligent.” <br>
        </p>
      </section>
      <section id="jobs" class="mb-5">
        <h2>Will AI Replace Jobs?</h2>
        <p>
            Rahman believes that AI’s effects on job markets will unfold gradually. “We're not likely to see mass layoffs, or mass increases in productivity either,” he said. <br>
            <br>
            Much of the discourse around AI reflects the “innovation fallacy,” or the belief that major advancements in technology automatically drive sweeping social change. <br> 
            <br>
            “Technology's capabilities rarely predict its impact on workers or the labor market. Instead, it's social, cultural, and organizational factors,” Rahman said. <br> 
            <br>
            Although AI developers are rapidly innovating, many organizations are slow to adopt AI tools because of concerns with data security, for example.  <br>
            <br>
            According to Rahman, a key consideration as AI’s workplace effects unfold is “occupational power”—that is, workers’ ability to shape how technology and other changes are implemented in their jobs. Lawyers, protected by bar association rules, have largely kept AI out of courtrooms, while customer service workers face more disruption from automation. <br>
            <br>
            Some professions have integrated AI in ways that enhance efficiency while maintaining or even increasing job quality. For instance, Rahman points out that while the technology to automate commercial flying has existed for decades, we are not yet traveling in self-flying planes. Instead, pilots’ wages have increased, and so has safety. <br>
        </p>
      </section>
    </article>

    <aside class="bg-light p-4 rounded">
      <h3>Quick Facts</h3>
      <p>Did you know?</p>
      <ul>
        <li>AI is used in agriculture and climate science</li>
        <li>Over 70% of businesses are adopting AI</li>
        <li>Bias in AI is a major concern</li>
      </ul>
    </aside>
  </main>

  <footer class="text-center text-white bg-dark py-3">
    <p>&copy; 2025 AI Revolution</p>
  </footer>
</body>
</html>
